---
layout: post
title: "GC Forest"
author: "Richard Penfil"
categories: Algorithm
tags: [GC Forest, Machine Learning]
image: accelerometer.jpg
---

Below is an example of a GC Forest model built using code from https://github.com/kingfengji/gcForest and data from https://www.kaggle.com/malekzadeh/motionsense-dataset. This dataset includes time-series data generated by accelerometer and gyroscope sensors. I will focus on the accelerometer data.


```python
from datetime import datetime
startTime = datetime.now()

import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
from scipy import stats
import tensorflow as tf
import seaborn as sns
from pylab import rcParams
import sklearn
from sklearn import metrics
from sklearn.cross_validation import train_test_split
from utils import (checking_na, now, proc_import)
%matplotlib inline
```

# Load Data


```python
#Combine & Label Datasets (excluding downstairs vs upstairs)
download_dir = 'combined.csv'

folders = ['jog_9','jog_16','sit_5','sit_13','std_6'
    ,'std_14','wlk_7','wlk_8','wlk_15']

for folder in folders:
    for num in range(1,25):
        filepath='C:\\Users\\user0\\Desktop\\Projects\\MotionSense\\A_DeviceMotion_data\\A_DeviceMotion_data\\' + folder + '\\sub_' + str(num) + '.csv'
        print(filepath)
        dataset=pd.read_csv(filepath)
        dataset['label']=num
        dataset['subject']=folder[:3]
        with open(download_dir,'a') as f:
            dataset.to_csv(f,header=False)

print(datetime.now()-startTime)
    
```

    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_1.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_2.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_3.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_4.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_5.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_6.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_7.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_8.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_9.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_10.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_11.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_12.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_13.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_14.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_15.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_16.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_17.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_18.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_19.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_20.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_21.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_22.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_23.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_9\sub_24.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_1.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_2.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_3.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_4.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_5.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_6.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_7.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_8.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_9.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_10.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_11.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_12.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_13.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_14.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_15.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_16.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_17.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_18.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_19.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_20.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_21.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_22.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_23.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\jog_16\sub_24.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_1.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_2.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_3.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_4.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_5.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_6.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_7.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_8.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_9.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_10.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_11.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_12.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_13.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_14.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_15.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_16.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_17.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_18.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_19.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_20.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_21.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_22.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_23.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_5\sub_24.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_1.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_2.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_3.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_4.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_5.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_6.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_7.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_8.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_9.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_10.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_11.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_12.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_13.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_14.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_15.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_16.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_17.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_18.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_19.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_20.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_21.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_22.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_23.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\sit_13\sub_24.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_1.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_2.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_3.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_4.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_5.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_6.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_7.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_8.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_9.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_10.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_11.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_12.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_13.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_14.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_15.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_16.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_17.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_18.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_19.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_20.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_21.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_22.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_23.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_6\sub_24.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_1.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_2.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_3.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_4.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_5.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_6.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_7.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_8.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_9.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_10.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_11.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_12.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_13.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_14.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_15.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_16.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_17.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_18.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_19.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_20.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_21.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_22.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_23.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\std_14\sub_24.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_1.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_2.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_3.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_4.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_5.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_6.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_7.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_8.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_9.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_10.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_11.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_12.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_13.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_14.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_15.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_16.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_17.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_18.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_19.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_20.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_21.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_22.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_23.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_7\sub_24.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_1.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_2.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_3.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_4.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_5.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_6.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_7.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_8.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_9.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_10.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_11.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_12.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_13.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_14.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_15.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_16.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_17.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_18.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_19.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_20.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_21.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_22.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_23.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_8\sub_24.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_1.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_2.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_3.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_4.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_5.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_6.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_7.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_8.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_9.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_10.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_11.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_12.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_13.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_14.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_15.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_16.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_17.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_18.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_19.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_20.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_21.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_22.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_23.csv
    C:\Users\user0\Desktop\Projects\MotionSense\A_DeviceMotion_data\A_DeviceMotion_data\wlk_15\sub_24.csv
    0:35:29.516010
    


```python
df=pd.read_csv('combined.csv', header=None)
df=df.iloc[:,2:]
```


```python
#Add Header
filepath='C:\\Users\\user0\\Desktop\\Projects\\MotionSense\\A_DeviceMotion_data\\A_DeviceMotion_data\\wlk_15\\sub_1.csv'
example=pd.read_csv(filepath)
col_names = example.columns
col_names = col_names[1:]
added = (['user','activity'])
col_names = np.append(col_names, added)
print(col_names)
```

    ['attitude.roll' 'attitude.pitch' 'attitude.yaw' 'gravity.x' 'gravity.y'
     'gravity.z' 'rotationRate.x' 'rotationRate.y' 'rotationRate.z'
     'userAcceleration.x' 'userAcceleration.y' 'userAcceleration.z' 'user'
     'activity']
    


```python
df.columns = col_names
df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>attitude.roll</th>
      <th>attitude.pitch</th>
      <th>attitude.yaw</th>
      <th>gravity.x</th>
      <th>gravity.y</th>
      <th>gravity.z</th>
      <th>rotationRate.x</th>
      <th>rotationRate.y</th>
      <th>rotationRate.z</th>
      <th>userAcceleration.x</th>
      <th>userAcceleration.y</th>
      <th>userAcceleration.z</th>
      <th>user</th>
      <th>activity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.058304</td>
      <td>-1.227988</td>
      <td>2.570999</td>
      <td>0.027964</td>
      <td>0.941814</td>
      <td>0.334969</td>
      <td>0.160508</td>
      <td>-1.386834</td>
      <td>-0.749713</td>
      <td>0.204199</td>
      <td>0.172657</td>
      <td>-0.801048</td>
      <td>1</td>
      <td>jog</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3.075964</td>
      <td>-1.225818</td>
      <td>2.615277</td>
      <td>0.022178</td>
      <td>0.941083</td>
      <td>0.337448</td>
      <td>-0.217198</td>
      <td>-0.612402</td>
      <td>-0.682841</td>
      <td>0.089974</td>
      <td>-0.373914</td>
      <td>-0.506332</td>
      <td>1</td>
      <td>jog</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.103364</td>
      <td>-1.235013</td>
      <td>2.651791</td>
      <td>0.012594</td>
      <td>0.944152</td>
      <td>0.329269</td>
      <td>0.663253</td>
      <td>-0.498534</td>
      <td>-0.620223</td>
      <td>0.260127</td>
      <td>-0.364364</td>
      <td>-0.781249</td>
      <td>1</td>
      <td>jog</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.109208</td>
      <td>-1.244901</td>
      <td>2.678484</td>
      <td>0.010366</td>
      <td>0.947364</td>
      <td>0.319989</td>
      <td>0.458100</td>
      <td>-1.202168</td>
      <td>-0.304561</td>
      <td>0.584253</td>
      <td>-0.922813</td>
      <td>-0.285169</td>
      <td>1</td>
      <td>jog</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3.074214</td>
      <td>-1.263514</td>
      <td>2.661371</td>
      <td>0.020364</td>
      <td>0.953159</td>
      <td>0.301783</td>
      <td>1.347809</td>
      <td>-0.550578</td>
      <td>0.610944</td>
      <td>0.626501</td>
      <td>-1.045978</td>
      <td>-0.063884</td>
      <td>1</td>
      <td>jog</td>
    </tr>
  </tbody>
</table>
</div>



# EDA


```python
df['activity'].value_counts().plot(kind='bar',
                                   title='Training examples by activity type');
```


![png](GC_Forest_files/GC_Forest_8_0.png)



```python
df['user'].value_counts().plot(kind='bar', title='Training examples by user');
```


![png](GC_Forest_files/GC_Forest_9_0.png)



```python
def plot_activity(activity, df):
    data = df[df['activity'] == activity][['userAcceleration.x', 
                                           'userAcceleration.y', 'userAcceleration.z']][:200]
    axis = data.plot(subplots=True, figsize=(16, 12), 
                     title=activity)
    for ax in axis:
        ax.legend(loc='lower left', bbox_to_anchor=(1.0, 0.5))
plot_activity("wlk", df)
```


![png](GC_Forest_files/GC_Forest_10_0.png)



```python
plot_activity("sit", df)
```


![png](GC_Forest_files/GC_Forest_11_0.png)



```python
plot_activity("std", df)
```


![png](GC_Forest_files/GC_Forest_12_0.png)



```python
plot_activity("jog", df)
```


![png](GC_Forest_files/GC_Forest_13_0.png)


# Preprocess Data


```python
#Preprocess Data
N_TIME_STEPS = 200
N_FEATURES = 3
step = 20
segments = []
labels = []
for i in range(0, len(df) - N_TIME_STEPS, step):
    xs = df['userAcceleration.x'].values[i: i + N_TIME_STEPS]
    ys = df['userAcceleration.y'].values[i: i + N_TIME_STEPS]
    zs = df['userAcceleration.z'].values[i: i + N_TIME_STEPS]
    label = stats.mode(df['activity'][i: i + N_TIME_STEPS])[0][0]
    segments.append([xs, ys, zs])
    labels.append(label)
np.array(segments).shape

reshaped_segments = np.asarray(segments,
                               dtype= np.float32).reshape(-1, N_TIME_STEPS, N_FEATURES)
labels = sklearn.preprocessing.LabelEncoder().fit_transform(labels)
reshaped_segments.shape

X_train, X_test, y_train, y_test = train_test_split(
        reshaped_segments, labels, test_size=0.1, random_state=7)
```


```python
X_train = X_train[:, np.newaxis, :, :]
X_test = X_test[:, np.newaxis, :, :]
```

# GC Forest


```python
import argparse
import numpy as np
import sys
from keras.datasets import mnist
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
sys.path.insert(0, "lib")
from gcforest.gcforest import GCForest
from gcforest.utils.config_utils import load_json

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", dest="model", type=str, default=None, help="gcfoest Net Model File")
    args = parser.parse_args()
    return args

def get_toy_config():
    config = {}
    ca_config = {}
    ca_config["random_state"] = 0
    ca_config["max_layers"] = 3
    ca_config["early_stopping_rounds"] = 3
    ca_config["n_classes"] = 4
    ca_config["estimators"] = []
    ca_config["estimators"].append({"n_folds": 5,
                                    "type": "XGBClassifier",
                                    "n_estimators": 10,
                                    "max_depth": 5,
                                    "objective": "multi:softprob", 
                                    "silent": True,
                                    "nthread": -1,
                                    "learning_rate": 0.1} )
    ca_config["estimators"].append({"n_folds": 5,
                                    "type": "RandomForestClassifier",
                                    "n_estimators": 10,
                                    "max_depth": None,
                                    "n_jobs": -1})
    ca_config["estimators"].append({"n_folds": 5,
                                    "type": "ExtraTreesClassifier",
                                    "n_estimators": 10,
                                    "max_depth": None,
                                    "n_jobs": -1})
    ca_config["estimators"].append({"n_folds": 5,
                                    "type": "LogisticRegression"})
    config["cascade"] = ca_config
    return config

```

Set the hyperparameters


```python
#config = load_json('gcforest/demo_mnist-ca.json')
gc = GCForest(get_toy_config())
```


```python
gc.set_keep_model_in_mem(False)
```


```python
X_train_enc = gc.fit_transform(X_train, y_train)
```

    [ 2018-05-16 08:15:55,328][cascade_classifier.fit_transform] X_groups_train.shape=[(50559, 200, 3)],y_train.shape=(50559,),X_groups_test.shape=no_test,y_test.shape=no_test
    [ 2018-05-16 08:15:55,390][cascade_classifier.fit_transform] group_dims=[600]
    [ 2018-05-16 08:15:55,390][cascade_classifier.fit_transform] group_starts=[0]
    [ 2018-05-16 08:15:55,390][cascade_classifier.fit_transform] group_ends=[600]
    [ 2018-05-16 08:15:55,390][cascade_classifier.fit_transform] X_train.shape=(50559, 600),X_test.shape=(0, 600)
    [ 2018-05-16 08:15:55,453][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(50559, 600), X_cur_test.shape=(0, 600)
    [ 2018-05-16 08:17:41,854][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_0.predict)=90.06%
    [ 2018-05-16 08:19:28,694][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_1.predict)=90.31%
    [ 2018-05-16 08:21:15,283][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_2.predict)=90.20%
    [ 2018-05-16 08:23:01,592][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_3.predict)=90.36%
    [ 2018-05-16 08:24:48,119][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_4.predict)=90.75%
    [ 2018-05-16 08:24:48,134][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_cv.predict)=90.34%
    [ 2018-05-16 08:24:53,291][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_0.predict)=95.20%
    [ 2018-05-16 08:24:59,073][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_1.predict)=95.33%
    [ 2018-05-16 08:25:04,452][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_2.predict)=95.33%
    [ 2018-05-16 08:25:09,766][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_3.predict)=95.30%
    [ 2018-05-16 08:25:14,898][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_4.predict)=95.60%
    [ 2018-05-16 08:25:14,913][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_cv.predict)=95.35%
    [ 2018-05-16 08:25:17,273][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_0.predict)=94.82%
    [ 2018-05-16 08:25:19,601][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_1.predict)=95.51%
    [ 2018-05-16 08:25:21,953][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_2.predict)=95.73%
    [ 2018-05-16 08:25:24,366][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_3.predict)=95.37%
    [ 2018-05-16 08:25:26,810][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_4.predict)=95.59%
    [ 2018-05-16 08:25:26,826][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_cv.predict)=95.40%
    [ 2018-05-16 08:25:54,485][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_3 - 5_folds.train_0.predict)=62.70%
    [ 2018-05-16 08:26:20,300][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_3 - 5_folds.train_1.predict)=62.26%
    [ 2018-05-16 08:26:47,892][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_3 - 5_folds.train_2.predict)=61.82%
    [ 2018-05-16 08:27:15,223][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_3 - 5_folds.train_3.predict)=61.84%
    [ 2018-05-16 08:27:41,195][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_3 - 5_folds.train_4.predict)=62.09%
    [ 2018-05-16 08:27:41,211][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_3 - 5_folds.train_cv.predict)=62.14%
    [ 2018-05-16 08:27:41,211][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=96.19%
    [ 2018-05-16 08:27:41,289][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(50559, 616), X_cur_test.shape=(0, 616)
    [ 2018-05-16 08:29:29,547][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_0.predict)=96.58%
    [ 2018-05-16 08:31:18,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_1.predict)=96.66%
    [ 2018-05-16 08:33:07,092][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_2.predict)=96.87%
    [ 2018-05-16 08:34:55,130][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_3.predict)=96.63%
    [ 2018-05-16 08:36:44,859][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_4.predict)=96.90%
    [ 2018-05-16 08:36:44,859][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_cv.predict)=96.73%
    [ 2018-05-16 08:36:49,661][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_0.predict)=96.71%
    [ 2018-05-16 08:36:54,458][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_1.predict)=96.81%
    [ 2018-05-16 08:36:59,474][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_2.predict)=96.87%
    [ 2018-05-16 08:37:04,146][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_3.predict)=96.71%
    [ 2018-05-16 08:37:08,881][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_4.predict)=96.80%
    [ 2018-05-16 08:37:08,896][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_cv.predict)=96.78%
    [ 2018-05-16 08:37:10,737][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_0.predict)=96.75%
    [ 2018-05-16 08:37:12,624][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_1.predict)=96.77%
    [ 2018-05-16 08:37:14,426][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_2.predict)=96.78%
    [ 2018-05-16 08:37:16,254][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_3.predict)=96.81%
    [ 2018-05-16 08:37:18,005][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_4.predict)=96.88%
    [ 2018-05-16 08:37:18,020][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_cv.predict)=96.80%
    [ 2018-05-16 08:37:53,555][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_3 - 5_folds.train_0.predict)=96.08%
    [ 2018-05-16 08:38:28,903][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_3 - 5_folds.train_1.predict)=96.41%
    [ 2018-05-16 08:39:03,120][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_3 - 5_folds.train_2.predict)=96.21%
    [ 2018-05-16 08:39:37,092][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_3 - 5_folds.train_3.predict)=96.45%
    [ 2018-05-16 08:40:10,908][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_3 - 5_folds.train_4.predict)=96.39%
    [ 2018-05-16 08:40:10,924][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_3 - 5_folds.train_cv.predict)=96.31%
    [ 2018-05-16 08:40:10,924][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=97.01%
    [ 2018-05-16 08:40:11,033][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(50559, 616), X_cur_test.shape=(0, 616)
    [ 2018-05-16 08:41:57,654][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_0.predict)=97.26%
    [ 2018-05-16 08:43:46,838][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_1.predict)=97.14%
    [ 2018-05-16 08:45:33,443][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_2.predict)=97.21%
    [ 2018-05-16 08:47:19,658][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_3.predict)=97.48%
    [ 2018-05-16 08:49:09,040][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_4.predict)=97.24%
    [ 2018-05-16 08:49:09,056][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_cv.predict)=97.27%
    [ 2018-05-16 08:49:13,409][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_0.predict)=96.83%
    [ 2018-05-16 08:49:17,572][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_1.predict)=96.89%
    [ 2018-05-16 08:49:22,047][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_2.predict)=96.98%
    [ 2018-05-16 08:49:26,427][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_3.predict)=97.21%
    [ 2018-05-16 08:49:30,677][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_4.predict)=97.13%
    [ 2018-05-16 08:49:30,693][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_cv.predict)=97.01%
    [ 2018-05-16 08:49:32,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_0.predict)=97.11%
    [ 2018-05-16 08:49:34,417][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_1.predict)=97.10%
    [ 2018-05-16 08:49:36,393][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_2.predict)=97.30%
    [ 2018-05-16 08:49:38,299][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_3.predict)=97.11%
    [ 2018-05-16 08:49:40,170][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_4.predict)=97.14%
    [ 2018-05-16 08:49:40,186][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_cv.predict)=97.15%
    [ 2018-05-16 08:50:11,470][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_3 - 5_folds.train_0.predict)=97.00%
    [ 2018-05-16 08:50:43,271][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_3 - 5_folds.train_1.predict)=97.10%
    [ 2018-05-16 08:51:13,711][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_3 - 5_folds.train_2.predict)=96.94%
    [ 2018-05-16 08:51:44,965][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_3 - 5_folds.train_3.predict)=97.20%
    [ 2018-05-16 08:52:17,124][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_3 - 5_folds.train_4.predict)=97.19%
    [ 2018-05-16 08:52:17,124][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_3 - 5_folds.train_cv.predict)=97.09%
    [ 2018-05-16 08:52:17,124][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=97.32%
    [ 2018-05-16 08:52:17,156][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=3, accuracy_train=97.32%, accuracy_test=0.00%
    

As seen above, the model reached above 97% accuracy within 3 layers. I manually stopped it after three as the next couple layers didn't add significant lift. Nevertheless, the model ran much faster than the LSTM RNN I ran on the same dataset.


```python
# You can try passing X_enc to another classfier on top of gcForest.e.g. xgboost/RF.
X_test_enc = gc.transform(X_test)
X_train_enc = X_train_enc.reshape((X_train_enc.shape[0], -1))
X_test_enc = X_test_enc.reshape((X_test_enc.shape[0], -1))
X_train_origin = X_train.reshape((X_train.shape[0], -1))
X_test_origin = X_test.reshape((X_test.shape[0], -1))
X_train_enc = np.hstack((X_train_origin, X_train_enc))
X_test_enc = np.hstack((X_test_origin, X_test_enc))
print("X_train_enc.shape={}, X_test_enc.shape={}".format(X_train_enc.shape, X_test_enc.shape))
clf = RandomForestClassifier(n_estimators=1000, max_depth=None, n_jobs=-1)
clf.fit(X_train_enc, y_train)
y_pred = clf.predict(X_test_enc)
acc = accuracy_score(y_test, y_pred)

print("Test Accuracy of Other classifier using gcforest's X_encode = {:.2f} %".format(acc * 100))
```


```python
# SAVE MODEL
with open("test.pkl", "wb") as f:
    pickle.dump(gc, f, pickle.HIGHEST_PROTOCOL)
# LOAD MODEL
with open("test.pkl", "rb") as f:
    gc = pickle.load(f)
y_pred = gc.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print("Test Accuracy of GcForest (save and load) = {:.2f} %".format(acc * 100))
```

    [ 2018-05-16 08:52:25,462][cascade_classifier.transform] X_groups_test.shape=[(5618, 200, 3)]
    [ 2018-05-16 08:52:25,650][cascade_classifier.transform] group_dims=[600]
    [ 2018-05-16 08:52:25,650][cascade_classifier.transform] X_test.shape=(5618, 600)
    [ 2018-05-16 08:52:25,665][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(5618, 600)
    [ 2018-05-16 08:52:27,400][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(5618, 616)
    [ 2018-05-16 08:52:29,072][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(5618, 616)
    

    Test Accuracy of GcForest (save and load) = 98.34 %
    

#### Confusion Matrix


```python
#Confusion Matrix
LABELS = ['Jogging', 'Sitting', 'Standing', 'Walking']
confusion_matrix = metrics.confusion_matrix(y_test, y_pred)
plt.figure(figsize=(16, 14))
sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt="d",cmap="YlGnBu",cbar=False);
plt.title("Confusion matrix")
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show();
```


![png](GC_Forest_files/GC_Forest_27_0.png)


#### Precision and Recall


```python
#PRECISION AND RECALL
report = sklearn.metrics.classification_report( y_test, y_pred )
print(report)
```

                 precision    recall  f1-score   support
    
              0       1.00      0.99      0.99       676
              1       0.97      0.98      0.98      1708
              2       0.98      0.97      0.97      1590
              3       1.00      1.00      1.00      1644
    
    avg / total       0.98      0.98      0.98      5618
    
    

Overall, The GC Forest had slightly better accuracy, and took less time to train than the LTSM model run on the same data.

# Reduced Training Sample
The authors of GC forest claim that it would require less data to train than a deep neural network. To test this hypothesis, I reran the above code with only 20% in the Training data.


```python
X_train, X_test, y_train, y_test = train_test_split(
        reshaped_segments, labels, test_size=0.8, random_state=7)
```

The results trained with only 20% were comparable to the results trained with 90%.

             precision    recall  f1-score   support

          0       1.00      0.99      0.99      5306
          1       0.96      0.96      0.96     13594
          2       0.95      0.96      0.95     12217
          3       0.99      1.00      1.00     13825

avg / total       0.97      0.97      0.97     44942

Unlike the results for the LSTM model, which had issues identifying sitting(2) vs standing(3) using only 20% of the data in the training set. 

             precision    recall  f1-score   support

          0       1.00      0.99      0.99      5306
          1       0.68      0.80      0.73     13594
          2       0.72      0.58      0.64     12217
          3       1.00      1.00      1.00     13825

avg / total       0.82      0.82      0.82     44942

In conclusion, the GC-Forest outperformed the LSTM model on this dataset both using 90% or 20% as training data.


```python

```
